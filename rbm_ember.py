
#### Libraries
# Standard library
import os
from time import time
#save model
import joblib
import pickle
# Own library, Joint
from rbm import Joint as jRBM
from ember_data import *
from tqdm import tqdm
from multiprocessing import Pool

# Third-party libraries
import math
import scipy
import numpy as np
from sklearn.preprocessing import StandardScaler, MinMaxScaler
from sklearn.metrics import confusion_matrix, classification_report
from sklearn.utils import shuffle
from matplotlib import pyplot as plt

def ember_skript(binary, trainX, trainY, nrHiddenUnits_p, train_size, batch_size,  modelsav):
    rnGen=np.random.RandomState(1234)
    data_path = 'data\ember'
    model="joint"
    errorThreshold=5
    lr,scal, momentum_p, CDk_p=0.01,0.01,0.0,1 
    initBiasZero=False
    nrEpochs_p = 50
    nrOfIter = 100
    plotMSE=True

    dataobj=EMBER()
    t0=time()
    print "shuffling: "
    trainX, trainY = shuffle(trainX, trainY, random_state=0)
    trainX, trainY=trainX[:train_size,:],trainY[:train_size]
    # print trainY[:20]
    # print "Binarizing: "
    # otf(dataobj, data_path ,trainX, trainY, testX, testY)
    # if (binary == True):
    #     trainX = binarize(trainX,0.5)
    #     testX = binarize(testX,0.5)
    ## important, because the first 2000 dataset are 0
    print("X train shape: ", trainX.shape)
    print("Y train shape: ", trainY.shape)
    print "training with Joint" 
    if (model == 'joint'):
        nrVisibleUnits = len(trainX[1])
        print "num of visible units: ", nrVisibleUnits
        nrTargetUnits = len(trainY[1])
        print "num of Hidden units: ", nrHiddenUnits_p
        print "num of target units: ", nrTargetUnits
        numOfBatches = trainX.shape[0] / batch_size
        print "Batch size: ", batch_size
        print "num of BATCH: ", numOfBatches
        jRBM1 = jRBM(nrVisibleUnits, nrHiddenUnits_p, nrTargetUnits, 
                     scal = scal, binary=binary, rnGen=rnGen, 
                     initBiasZero=initBiasZero)
        epoch=0
        #initialize mean errors on data and labels
        mErrorX = 0
        mErrorY = 0
        mEs = np.zeros(nrEpochs_p+1)
        print 'Training joint-probabilities model of RBM...'
        t1=time()
        while epoch<nrEpochs_p:
            t2=time()
            epoch+=1
            print "training epoch: ", epoch
            for i in range(numOfBatches):
                # print "index in batch: ", i*batch_size, " to ",(i+1)*(batch_size)
                batchX=trainX[i*batch_size:(i+1)*(batch_size)]
                batchY=trainY[i*batch_size:(i+1)*(batch_size)]
                gWVH, gWTH, gV, gT, gH, eX, eY = jRBM1.train(batchX, batchY, errorThreshold, k=CDk_p)
                jRBM1.updateWeight(lr, gWVH, gWTH, gV, gT, gH ,momentum = momentum_p)
                mErrorX += eX
                mErrorY += eY
            #print mean error on data and labels
            mErrorX /= numOfBatches
            mEs[epoch] = mErrorX
            mErrorY /= numOfBatches
            print "MSE for epoch %d: on data: %0.3f, epoch time: %0.2f seconds" \
            % (epoch, mErrorX, time()-t2)
        print "WeightsVH: ", jRBM1.WeightsVH, jRBM1.WeightsVH.shape
        print "WeightsWTH: ", jRBM1.WeightsTH, jRBM1.WeightsTH.shape
        print "Hidden Baises: ", jRBM1.HiddenBiases, jRBM1.HiddenBiases.shape
        print "VisibleBiases: ", jRBM1.VisibleBiases, jRBM1.VisibleBiases.shape
        print "Target Biases: ", jRBM1.TargetBiases, jRBM1.TargetBiases.shape
        train_time=time()-t1
        print "Saving the model..."
        file_pickle=open(modelsav,'wb')
        pickle.dump(jRBM1, file_pickle)
        file_pickle.close()
        print "Mean Squared Error", mEs
        if plotMSE:
            #Plot mean squared error on data within epochs
            plt.figure()
            plt.title('Mean squared error for epochs')
            plt.plot(mEs, 'b', label='Model with non-varied momentum rate')
            plt.legend()
            plt.grid()
            plt.xlabel('Epoch')
            plt.ylabel('Mean-squared weight error')
            plt.xlim(xmin=1)
            # plt.show()
            fname=modelsav[-4]+".png"
            plt.savefig(fname)

def perform_predict(binary, testX, testY, modelsav,resultsav, method=2):
    data_path='data\ember'
    dataobj=EMBER()
    test_size=1000
    nrOfIter = 50

    file_pickle=open(modelsav,'rb')
    jRBM1=pickle.load(file_pickle)
    print('Performing classification on test data...')
    t3=time()

    testX,testY=testX[:test_size,:],testY[:test_size]
    if method==2:
        label = jRBM1.predict2(testX)
    else:
        label = jRBM1.predict(testX, nrOfIter)
    np.savetxt(resultsav, label, delimiter=",")
    predict_time = time()-t3

    counter = 0
    for i in range(len(label)):
        #print "Reconstrlabel is %f, original label is%f" % (label[i],testY[i]) 
        # if label[i] != testY[i]:
        # print "label", i, ": ", label[i]
        if label[i].astype(int)!=testY[i].astype(int):
            #test_data = testX[i]
            counter +=1
            #print wrongly predicted
            #print "Reconstrlabel is %f, original label is%f" % (label[i],testY[i]) 
    err = counter / float(len(label))
    acc = 1 - err
    print "Classification error is %0.3f" % err
    print "Accuracy is %0.3f" % acc
    print "Confusion matrix:" 
    print  confusion_matrix(label.astype(int),testY.astype(int))
    print "Classification report:" 
    print  classification_report(label.astype(int),testY.astype(int))
    print "Prediction time is %0.3fs" % predict_time
    print "RBM predicted"

def ember_skript_unpack(args):
    return ember_skript(*args)

def train_multiple():
    ndim = 2381 # default feature version2
    data_path = "data\ember"
    print "Reading data"
    print "Reading y"
    
    y_train_path = os.path.join(data_path, "tL2fy_train.dat")
    y_train = np.memmap(y_train_path, dtype=np.float32, mode="r", shape=(600000,2))
    y_test_path = os.path.join(data_path, "y_test.dat")
    y_test = np.memmap(y_test_path, dtype=np.float32, mode="r")
    print "Reading X"
    ftrainX_path =os.path.join(data_path, "fX_train.dat")
    ftrainX = np.memmap(ftrainX_path, dtype = np.float32, mode="r", shape = (600000, ndim))
    testX_path = os.path.join(data_path, "X_test.dat")
    testX = np.memmap(testX_path, dtype = np.float32, mode="r", shape = (200000, ndim))
    # ftrainX = np.zeros((600000,ndim))
    # testX = np.zeros((200000, ndim))
    print "Reading mmstdfX"
    mmstdftrainX_path = os.path.join(data_path, "mmstdfX_train.dat")
    mmstdtestX_path   = os.path.join(data_path, "mmstdX_test.dat")
    mmstdftrainX_mem = np.memmap(mmstdftrainX_path,dtype=np.float32, mode = "r",shape=ftrainX.shape)
    mmstdtestX_mem   = np.memmap(mmstdtestX_path,dtype=np.float32, mode = "r",shape=testX.shape)
    print "Reading bmmstdfX"
    bmmstdftrainX_path = os.path.join(data_path, "bmmstdfX_train.dat")
    bmmstdtestX_path   = os.path.join(data_path, "bmmstdX_test.dat")
    bmmstdftrainX_mem = np.memmap(bmmstdftrainX_path,dtype=np.float32, mode = "r",shape=ftrainX.shape)
    bmmstdtestX_mem   = np.memmap(bmmstdtestX_path,dtype=np.float32, mode = "r",shape=testX.shape)
    print "Reading mmfX"
    mmftrainX_path = os.path.join(data_path, "mmfX_train.dat")
    mmtestX_path   = os.path.join(data_path, "mmX_test.dat")
    mmftrainX_mem = np.memmap(mmftrainX_path,dtype=np.float32, mode = "r",shape=ftrainX.shape)
    mmtestX_mem   = np.memmap(mmtestX_path,dtype=np.float32, mode = "r",shape=testX.shape)
    print "Reading bmmfX"
    bmmftrainX_path = os.path.join(data_path, "bmmfX_train.dat")
    bmmtestX_path   = os.path.join(data_path, "bmmX_test.dat")
    bmmftrainX_mem = np.memmap(bmmftrainX_path,dtype=np.float32, mode = "r",shape=ftrainX.shape)
    bmmtestX_mem   = np.memmap(bmmtestX_path,dtype=np.float32, mode = "r",shape=testX.shape)

    binary_list = [False, True, False, True, False]
    trainX_list = [mmstdftrainX_mem, bmmstdftrainX_mem, mmftrainX_mem,  bmmftrainX_mem, ftrainX]
    testX_list =  [mmstdtestX_mem,   bmmstdtestX_mem,   mmtestX_mem, bmmtestX_mem, testX]
    modelsav_list = ["JRBM_mmstdf.sav", "JRBM_bmmstdf.sav", "JRBM_mmf.sav", "JRBM_bmmf.sav", "JRBM_f.sav"]
    result_list =   ["JRBM_mmstdf.csv", "JRBM_bmmstdf.csv", "JRBM_mmf.csv", "JRBM_bmmf.csv", "JRBM_f.csv"]
    # nrHiddenUnits_p_list = [128, 256, 512, 1024]   
    # train size , nr Epoch
    params = {128: [10000, 100], 256: [5000, 50], 512: [2500, 50], 1024:[1250, 50]}
    # ember_skript(binary, trainX, trainY, nrHiddenUnits_p, train_size, batch_size,  modelsav)
    pool = Pool(5)
    process_list = []
    for i in range(5):
        process_list.append(pool.apply_async(single_process, (params, modelsav_list, i, binary_list, trainX_list, y_train,)))
    
    pool.close()
    pool.join()
    print "Wait for all process done."

    
    modelsav_arr = np.array(modelsav_list).reshape((5,4))
    print modelsav_arr
    for i in range(5):
        for j in range(4):
            name = result_list[i]+str(time())[:-3]
            perform_predict(binary_list[i], testX_list[i], y_test, modelsav_arr[i,j], name, 2)

def single_process(params, modelsav_list, i, binary_list, trainX_list, y_train):
    for k,v in params.items():
        name = modelsav_list[i]+str(time())[:-3]
        print "i:",i, " nrHiddenUnits :", k," Train/batch size :", v
        print "model name: ", name
        modelsav_list.append(name)
        ember_skript(binary_list[i],trainX_list[i], y_train, k, v[0], v[1], name)




if __name__=='__main__':
    print "main function: "
    # # otf_transformLabel2()
    # print "otf_minmaxScale()..."
    # otf_minmaxScale()
    # print "otf_mmstdScale()..."
    # otf_mmstdScale()
    # print "train_multiple()..."
    # train_multiple()
    # print "perform_predict()"
    # perform_predict()
    


    